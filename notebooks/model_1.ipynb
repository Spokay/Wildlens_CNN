{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6b23234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers, models, losses\n",
    "from PIL import Image\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "class CustomDataGen(keras.utils.Sequence):\n",
    "    def __init__(self, data_folder: str, aug_len: dict[str, float], batch_size=32, split=\"train\", train_ratio=0.8, seed=42):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_folder = data_folder\n",
    "        self.aug_len = aug_len\n",
    "        self.batch_size = batch_size\n",
    "        self.data = []\n",
    "\n",
    "        self.pipeline = tf.keras.Sequential([\n",
    "            keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            keras.layers.RandomRotation(0.2),\n",
    "            keras.layers.RandomZoom(0.1),\n",
    "            keras.layers.RandomContrast(0.01),\n",
    "            keras.layers.Rescaling(1./255),\n",
    "            keras.layers.Resizing(224, 224),\n",
    "            keras.layers.Normalization(\n",
    "                mean=(0.485, 0.456, 0.406), \n",
    "                variance=(0.229, 0.224, 0.225)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.split = split\n",
    "        self.train_ratio = train_ratio\n",
    "        self.seed = seed\n",
    "        self.load_data()\n",
    "        self.classes = {label: idx for idx, label in enumerate(set([item[\"label\"] for item in self.data]))}\n",
    "\n",
    "    \n",
    "    def load_data(self):\n",
    "\n",
    "        all_files = []\n",
    "        for root, _, files in os.walk(self.data_folder):\n",
    "            ext = os.path.splitext(files[0])[1]\n",
    "            if ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                continue\n",
    "            subfolder = os.path.basename(root)\n",
    "            for file in files:\n",
    "                all_files.append({\n",
    "                    \"path\": os.path.join(root, file),\n",
    "                    \"label\": subfolder\n",
    "                })\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(all_files)\n",
    "        \n",
    "\n",
    "        split_idx = int(len(all_files) * self.train_ratio)\n",
    "        \n",
    "\n",
    "        if self.split == \"train\":\n",
    "            base_files = all_files[:split_idx]\n",
    "        else:\n",
    "            base_files = all_files[split_idx:]\n",
    "        \n",
    "\n",
    "        self.data = []\n",
    "        for file in base_files:\n",
    "            if self.split == \"train\" and file[\"label\"] in self.aug_len:\n",
    "                prob = self.aug_len[file[\"label\"]]\n",
    "                for _ in range(int(prob)):\n",
    "                    self.data.append(file)\n",
    "                if np.random.rand() < (prob - int(prob)):\n",
    "                    self.data.append(file)\n",
    "            else:\n",
    "                self.data.append(file)\n",
    "        \n",
    "        random.shuffle(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for item in batch_data:\n",
    "            img = Image.open(item[\"path\"])\n",
    "            img = np.array(img)\n",
    "            if img.ndim == 2:\n",
    "                img = np.stack((img,) * 3, axis=-1)\n",
    "            elif img.shape[2] == 1:\n",
    "                img = np.concatenate([img] * 3, axis=-1)\n",
    "            img = self.pipeline(img)\n",
    "            batch_images.append(img)\n",
    "            batch_labels.append(self.classes[item[\"label\"]])\n",
    "\n",
    "        return np.array(batch_images), np.array(batch_labels)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5e938e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CustomDataGen(\"/home/shared/Mammiferes_jpg\", {\"cat\": 1.5, \"dog\": 1.5}, batch_size=8, split=\"train\")\n",
    "test = CustomDataGen(\"/home/shared/Mammiferes_jpg\", {\"cat\": 1.5, \"dog\": 1.5}, batch_size=8, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c121b643a7ee534",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(13, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(train))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b403d5733d32e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:14.723890Z",
     "start_time": "2024-11-14T11:30:14.720689Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=losses.sparse_categorical_crossentropy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c376fe1c1c326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:19.899112Z",
     "start_time": "2024-11-14T11:30:15.199396Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3553b84483a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:19.982427Z",
     "start_time": "2024-11-14T11:30:19.899718Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(history.history[\"loss\"][2:10])\n",
    "plt.plot(history.history[\"val_loss\"][2:10])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d3fbac8dec1f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:20.182127Z",
     "start_time": "2024-11-14T11:30:19.982838Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(\"/home/shared/Mammiferes_jpg/Castor/original.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b350bd69be4478d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:20.192823Z",
     "start_time": "2024-11-14T11:30:20.182756Z"
    }
   },
   "outputs": [],
   "source": [
    "castor = tf.io.read_file(\"/home/shared/Mammiferes_jpg/Castor/original.jpeg\")\n",
    "castor = tf.image.decode_jpeg(castor, channels=3)\n",
    "resized_castor = tf.image.resize(castor, [256,256], method=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e39ae9d48da8266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:20.194611Z",
     "start_time": "2024-11-14T11:30:20.193253Z"
    }
   },
   "outputs": [],
   "source": [
    "input = tf.expand_dims(\n",
    "    resized_castor,\n",
    "    axis = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79e257aad3ba39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:21.679305Z",
     "start_time": "2024-11-14T11:30:21.677229Z"
    }
   },
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394bbc6c176e510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:22.935557Z",
     "start_time": "2024-11-14T11:30:22.810221Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0845126815984a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:30:28.337181Z",
     "start_time": "2024-11-14T11:30:28.304456Z"
    }
   },
   "outputs": [],
   "source": [
    "next(iter(test))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87525a502a892aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:36:20.803755Z",
     "start_time": "2024-11-14T11:36:20.802046Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = train.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c2aa780574493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:53:55.397024Z",
     "start_time": "2024-11-14T11:53:55.303868Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "batch,_ = test.take(3)\n",
    "plt.imshow(batch[0][1].numpy().astype(\"uint8\"))\n",
    "plt.title(class_names[batch[1][1]])\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbb4d9c95be4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:53:30.063219Z",
     "start_time": "2024-11-14T11:53:30.061909Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11aee173c5c597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5618c-3dc1-480a-95e3-c559e2e4f6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c4438-9be0-4686-9dbd-4c581c328eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec41253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e37cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
