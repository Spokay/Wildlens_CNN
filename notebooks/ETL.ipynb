{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f38bea-d2d6-42b9-b2d5-e5d95cd7c24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T14:25:41.055162Z",
     "start_time": "2024-11-14T14:25:40.088682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:25:40.182294: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-14 15:25:40.190564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-14 15:25:40.199658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-14 15:25:40.202465: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 15:25:40.209554: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 15:25:40.658513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731594341.031658   41219 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731594341.053527   41219 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1731594341.053671   41219 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e59d05feca7de",
   "metadata": {},
   "source": [
    "# Transformation de toutes les images en JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0357f92832fdf37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T14:25:49.461191Z",
     "start_time": "2024-11-14T14:25:47.378776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "from pathlib import PosixPath\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "data_dir_path = '/home/shared/Mammiferes'\n",
    "\n",
    "\n",
    "def transform_image_type_to_jpg(images: list[PosixPath]) -> None:\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        img = Image.open(image)\n",
    "        if img.mode in (\"RGBA\", \"P\"):\n",
    "            img = img.convert(\"RGB\")\n",
    "        # The image object is used to save the image in jpg format\n",
    "        img.save(image, 'JPEG')\n",
    "        i += 1\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(data_dir_path).with_suffix('')\n",
    "\n",
    "image_paths = list(data_dir.glob('*/*.*'))\n",
    "\n",
    "transform_image_type_to_jpg(image_paths)\n",
    "\n",
    "image_count = len(image_paths)\n",
    "\n",
    "print(image_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33951cbe3d44a0",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "949c70003328d63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T14:33:18.000128Z",
     "start_time": "2024-11-14T14:33:17.119963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(None, None, 3), dtype=uint8)\n",
      "Tensor(\"args_1:0\", shape=(), dtype=int64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [333,500,3] and element 1 had shape [247,320,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 74\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mzip((dataset, mapped_dataset))\n\u001b[1;32m     72\u001b[0m train_datasets: Dataset \u001b[38;5;241m=\u001b[39m train_datasets\u001b[38;5;241m.\u001b[39mapply(apply_augmentation)\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (image, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_datasets\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39miterator_get_next(\n\u001b[1;32m    777\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[1;32m    778\u001b[0m       output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    779\u001b[0m       output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes)\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   _ops\u001b[38;5;241m.\u001b[39mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [333,500,3] and element 1 had shape [247,320,3]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.data import AUTOTUNE\n",
    "from tensorflow.data import Dataset\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def visualize(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(original)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "\n",
    "\n",
    "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "image_width, image_height = (256, 256)\n",
    "\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "\n",
    "def resize_and_rescale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = (image / 255.0)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def augment_and_make_seed(x, y):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    seed = rng.make_seeds(1)[:, 0]\n",
    "    image, label = augment((x, y), seed)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def augment(image_label, seed):\n",
    "    image, label = image_label\n",
    "    image, label = resize_and_rescale(image, label)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, image_width + 6, image_height + 6)\n",
    "    # Make a new seed.\n",
    "    new_seed = tf.random.split(seed, num=1)[0, :]\n",
    "    # Random crop back to the original size.\n",
    "    image = tf.image.stateless_random_crop(\n",
    "        image, size=[image_width, image_height, 3], seed=seed)\n",
    "    # Random brightness.\n",
    "    image = tf.image.stateless_random_brightness(\n",
    "        image, max_delta=0.5, seed=new_seed)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def apply_augmentation(dataset: Dataset):\n",
    "    mapped_dataset = dataset.map(\n",
    "        augment_and_make_seed\n",
    "    )\n",
    "    return Dataset.zip((dataset, mapped_dataset))\n",
    "\n",
    "\n",
    "train_datasets: Dataset = train_datasets.apply(apply_augmentation).shuffle(1000).batch(32)\n",
    "\n",
    "for (image, label) in enumerate(train_datasets.take(5)):\n",
    "    print(image)\n",
    "    print(label)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
